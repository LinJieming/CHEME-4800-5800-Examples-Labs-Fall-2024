{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51dba82a-3861-41d1-beed-db31ad8afd46",
   "metadata": {},
   "source": [
    "# Example: Loading and Analysis of Sarcasm Dataset\n",
    "Fill me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69630fa3-1f48-4773-a08a-316ac749a680",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We set up the computational environment by including [the `Include. jl` file](Include.jl) using [the `include(...)` method](https://docs.julialang.org/en/v1/base/base/#Base.include). The [`Include.jl` file](Include.jl) loads external packages and functions we will use in these examples. \n",
    "* For additional information on functions and types used in this example, see the [Julia programming language documentation](https://docs.julialang.org/en/v1/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee9ce5a-bcd7-4e5a-890e-7fd1dc43c799",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316f88aa-17e9-492b-b7c1-63c57c930297",
   "metadata": {},
   "source": [
    "## Task 1: Load the sarcasm dataset\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167d0489-7541-48a7-9d04-dbb0c651f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = joinpath(_PATH_TO_DATA, \"Sarcasm_Headlines_Dataset_v2.txt\") |> corpus;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4c73e-d6e3-438a-bd0e-1551f2d1a8c5",
   "metadata": {},
   "source": [
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b93c527-3b77-4b11-8f47-01f62144aacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Any} with 3 entries:\n",
       "  \"article_link\" => \"https://www.theonion.com/thirtysomething-scientists-unveil…\n",
       "  \"is_sarcastic\" => 1\n",
       "  \"headline\"     => \"thirtysomething scientists unveil doomsday clock of hair l…"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.records[1].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cba7185-3d09-4ff9-a062-3b5a952198af",
   "metadata": {},
   "source": [
    "## Task 2: Build the tokens dictionary\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47a182fa-6292-4363-8043-a600e5d7e48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_records = dataset.records |> length; # what is going on here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ec9ae4-9c62-4332-98bd-d7212b2526ec",
   "metadata": {},
   "source": [
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b394822-694d-4c5a-848b-4f339c894fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenarray = Array{String,1}();\n",
    "for (k,v) ∈ dataset.records\n",
    "\n",
    "    # process headline data -\n",
    "    headline = v.data[\"headline\"]\n",
    "    tokens = split(headline, \" \") .|> String;\n",
    "\n",
    "    # process -\n",
    "    for token ∈ tokens\n",
    "\n",
    "        # strip any leading or trailing spaces -\n",
    "        token = strip(token, ' ');\n",
    "        \n",
    "        if (in(token, tokenarray) == false && isempty(token) == false)\n",
    "            push!(tokenarray, token);\n",
    "        end\n",
    "    end \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeec749b-dec4-41a7-bc33-a3762aa5c5d0",
   "metadata": {},
   "source": [
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f78b0b5-4027-47b2-a9b1-a5bab2bef31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29665-element Vector{String}:\n",
       " \"\"\n",
       " \"#\"\n",
       " \"##\"\n",
       " \"#1\"\n",
       " \"#11717\"\n",
       " \"#4\"\n",
       " \"#5\"\n",
       " \"#addcandytoamovie\"\n",
       " \"#addclimatechangetotv\"\n",
       " \"#alohahuffpost\"\n",
       " \"#alternativefacts\"\n",
       " \"#badpicturemonday\"\n",
       " \"#blacklivesmatter\"\n",
       " ⋮\n",
       " \"zoroastrianism\"\n",
       " \"zs\"\n",
       " \"zsa\"\n",
       " \"zucker\"\n",
       " \"zuckerberg\"\n",
       " \"zuckerbergs\"\n",
       " \"zz\"\n",
       " \" jacquie\"\n",
       " \" winner\"\n",
       " \"    \"\n",
       " \"éclairs\"\n",
       " \"ünited\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenarray |> sort!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0fbd42-56fa-4fe6-b0ae-86b59d550161",
   "metadata": {},
   "source": [
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26e38220-e676-4953-ae81-862c552d46f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokendictionary = Dict{String, Int64}();\n",
    "for i ∈ eachindex(tokenarray)\n",
    "    key = tokenarray[i]\n",
    "    tokendictionary[key] = i; \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae90c592-faae-42e4-91f7-8b5231068d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Int64} with 29665 entries:\n",
       "  \"rosecolored\"           => 22746\n",
       "  \"trumpland\"             => 27336\n",
       "  \"irreplaceable\"         => 14092\n",
       "  \"cluelessly\"            => 5598\n",
       "  \"syriaalthough\"         => 26086\n",
       "  \"bumbum\"                => 4205\n",
       "  \"#addclimatechangetotv\" => 9\n",
       "  \"dumber\"                => 8591\n",
       "  \"daraya\"                => 7073\n",
       "  \"jakrapong\"             => 14213\n",
       "  \"henry\"                 => 12551\n",
       "  \"skylight\"              => 24355\n",
       "  \"bidder\"                => 3240\n",
       "  \"abducted\"              => 935\n",
       "  \"rises\"                 => 22533\n",
       "  \"hampshire\"             => 12132\n",
       "  \"droogs\"                => 8493\n",
       "  \"whiz\"                  => 29009\n",
       "  \"buffetts\"              => 4153\n",
       "  \"il\"                    => 13308\n",
       "  \"celebfilled\"           => 4869\n",
       "  \"msnbc\"                 => 17516\n",
       "  \"starches\"              => 25204\n",
       "  \"tribunal\"              => 27224\n",
       "  \"lovers\"                => 15869\n",
       "  ⋮                       => ⋮"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokendictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dffdf9-1b61-4904-9128-4a6fc3afe560",
   "metadata": {},
   "source": [
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab0d7ef9-0d5c-4a37-8129-dd1b352fd7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.tokens = tokendictionary;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e58e3-e33b-45bb-8dab-1ef64d4b2679",
   "metadata": {},
   "source": [
    "## Task 3: Tokenize an example record\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b8f587-b23d-43eb-89be-df739f0c8ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
