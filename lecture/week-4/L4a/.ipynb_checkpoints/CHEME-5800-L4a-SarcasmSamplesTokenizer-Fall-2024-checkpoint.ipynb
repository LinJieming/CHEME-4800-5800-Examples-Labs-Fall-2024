{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51dba82a-3861-41d1-beed-db31ad8afd46",
   "metadata": {},
   "source": [
    "# Example: Loading and Analyzing the Sarcasm Dataset\n",
    "Fill me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69630fa3-1f48-4773-a08a-316ac749a680",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We set up the computational environment by including [the `Include. jl` file](Include.jl) using [the `include(...)` method](https://docs.julialang.org/en/v1/base/base/#Base.include). The [`Include.jl` file](Include.jl) loads external packages and functions we will use in these examples. \n",
    "* For additional information on functions and types used in this example, see the [Julia programming language documentation](https://docs.julialang.org/en/v1/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee9ce5a-bcd7-4e5a-890e-7fd1dc43c799",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316f88aa-17e9-492b-b7c1-63c57c930297",
   "metadata": {},
   "source": [
    "## Task 1: Load the sarcasm dataset\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167d0489-7541-48a7-9d04-dbb0c651f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = joinpath(_PATH_TO_DATA, \"Sarcasm_Headlines_Dataset_v2.txt\") |> corpus;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4c73e-d6e3-438a-bd0e-1551f2d1a8c5",
   "metadata": {},
   "source": [
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b93c527-3b77-4b11-8f47-01f62144aacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MySarcasmRecordModel(true, \"thirtysomething scientists unveil doomsday clock of hair loss\", \"https://www.theonion.com/thirtysomething-scientists-unveil-doomsday-clock-of-hai-1819586205\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.records[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c83f2903-67f8-42b7-bd8e-9e1ffae59c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, MySarcasmRecordModel}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(dataset.records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cba7185-3d09-4ff9-a062-3b5a952198af",
   "metadata": {},
   "source": [
    "## Task 2: Build the tokens dictionary\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a182fa-6292-4363-8043-a600e5d7e48d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1ec9ae4-9c62-4332-98bd-d7212b2526ec",
   "metadata": {},
   "source": [
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b394822-694d-4c5a-848b-4f339c894fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenarray = Array{String,1}();\n",
    "for (k,v) ∈ dataset.records\n",
    "\n",
    "    # process headline data -\n",
    "    headline = v.headline;\n",
    "    tokens = split(headline, \" \") .|> String;\n",
    "\n",
    "    # process -\n",
    "    for token ∈ tokens\n",
    "\n",
    "        # strip any leading or trailing spaces -\n",
    "        token = strip(token, ' ');\n",
    "        \n",
    "        if (in(token, tokenarray) == false && isempty(token) == false)\n",
    "            push!(tokenarray, token);\n",
    "        end\n",
    "    end \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeec749b-dec4-41a7-bc33-a3762aa5c5d0",
   "metadata": {},
   "source": [
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f78b0b5-4027-47b2-a9b1-a5bab2bef31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29662-element Vector{String}:\n",
       " \"#\"\n",
       " \"##\"\n",
       " \"#1\"\n",
       " \"#11717\"\n",
       " \"#4\"\n",
       " \"#5\"\n",
       " \"#addcandytoamovie\"\n",
       " \"#addclimatechangetotv\"\n",
       " \"#alohahuffpost\"\n",
       " \"#alternativefacts\"\n",
       " \"#badpicturemonday\"\n",
       " \"#blacklivesmatter\"\n",
       " \"#brownribboncampaign\"\n",
       " ⋮\n",
       " \"zoologists\"\n",
       " \"zoomed\"\n",
       " \"zoos\"\n",
       " \"zoroastrianism\"\n",
       " \"zs\"\n",
       " \"zsa\"\n",
       " \"zucker\"\n",
       " \"zuckerberg\"\n",
       " \"zuckerbergs\"\n",
       " \"zz\"\n",
       " \"éclairs\"\n",
       " \"ünited\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenarray |> sort!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed3e4789-2d11-4a42-93d5-952b36529b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"jacquie\" ∈ tokenarray "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0fbd42-56fa-4fe6-b0ae-86b59d550161",
   "metadata": {},
   "source": [
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26e38220-e676-4953-ae81-862c552d46f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokendictionary = Dict{String, Int64}();\n",
    "for i ∈ eachindex(tokenarray)\n",
    "    key = tokenarray[i]\n",
    "    tokendictionary[key] = i; \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae90c592-faae-42e4-91f7-8b5231068d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Int64} with 29662 entries:\n",
       "  \"rosecolored\"           => 22746\n",
       "  \"trumpland\"             => 27336\n",
       "  \"irreplaceable\"         => 14091\n",
       "  \"cluelessly\"            => 5597\n",
       "  \"syriaalthough\"         => 26086\n",
       "  \"bumbum\"                => 4204\n",
       "  \"#addclimatechangetotv\" => 8\n",
       "  \"dumber\"                => 8590\n",
       "  \"daraya\"                => 7072\n",
       "  \"jakrapong\"             => 14213\n",
       "  \"henry\"                 => 12550\n",
       "  \"skylight\"              => 24355\n",
       "  \"bidder\"                => 3239\n",
       "  \"abducted\"              => 934\n",
       "  \"rises\"                 => 22533\n",
       "  \"hampshire\"             => 12131\n",
       "  \"droogs\"                => 8492\n",
       "  \"whiz\"                  => 29009\n",
       "  \"buffetts\"              => 4152\n",
       "  \"il\"                    => 13307\n",
       "  \"celebfilled\"           => 4868\n",
       "  \"msnbc\"                 => 17516\n",
       "  \"starches\"              => 25204\n",
       "  \"tribunal\"              => 27224\n",
       "  \"lovers\"                => 15869\n",
       "  ⋮                       => ⋮"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokendictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dffdf9-1b61-4904-9128-4a6fc3afe560",
   "metadata": {},
   "source": [
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab0d7ef9-0d5c-4a37-8129-dd1b352fd7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.tokens = tokendictionary;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e58e3-e33b-45bb-8dab-1ef64d4b2679",
   "metadata": {},
   "source": [
    "## Task 3: Tokenize headline records\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9b8f587-b23d-43eb-89be-df739f0c8ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_records = dataset.records |> length; # what is going on here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b88331-3b29-4b31-beb0-5c0b33b0303d",
   "metadata": {},
   "source": [
    "### Look at a random record\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af4c6ce8-9464-4e6a-aac1-ce96d18a85fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MySarcasmRecordModel(false, \"8 super effective ways to use social media to land your next job\", \"https://www.huffingtonpost.com/entry/laid-off-how-and-why-to-tell-the-world-on-social-media_us_57bf095ce4b085c1ff28033b\")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_test_record = rand(1:number_of_records) |> i -> dataset.records[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4aaee86-09cf-4253-83df-6df46e1f571e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"8 super effective ways to use social media to land your next job\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_test_record.headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5add6a7f-6849-425d-9340-31c2208d9263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13-element Vector{Int64}:\n",
       "   819\n",
       " 25801\n",
       "  8823\n",
       " 28769\n",
       " 26825\n",
       " 28083\n",
       " 24669\n",
       " 16618\n",
       " 26825\n",
       " 15089\n",
       " 29544\n",
       " 18011\n",
       " 14386"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv = tokenize(random_test_record.headline, dataset.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523b4fca-8ae8-4aa5-9467-2966d8459035",
   "metadata": {},
   "source": [
    "### Compute the maximum pad length\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48bc335b-be7d-4c63-b8d8-25fea7aff46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pad_length = 0;\n",
    "for i ∈ 1:number_of_records\n",
    "    test_record_length = tokenize(dataset.records[i].headline, dataset.tokens) |> length;\n",
    "    if (test_record_length > max_pad_length)\n",
    "        max_pad_length = test_record_length;\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b802fe64-6dff-413e-a9da-0894de6b27ad",
   "metadata": {},
   "source": [
    "### Compute the number of sarcasm and non-sarcasm samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b03656-a739-46d9-9c47-c9acb2aa9edb",
   "metadata": {},
   "source": [
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2071212-6729-43b0-95c9-27d44c07723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_sarcasm_samples = 0;\n",
    "number_of_non_sarcasm_samples = 0;\n",
    "for i ∈ 1:number_of_records\n",
    "    \n",
    "    is_sarcastic_flag = dataset.records[i].issarcastic\n",
    "    if (is_sarcastic_flag == true)\n",
    "        number_of_sarcasm_samples += 1;\n",
    "    else\n",
    "        number_of_non_sarcasm_samples+=1;\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4b7ba5-4690-4671-9034-327b409eaf2d",
   "metadata": {},
   "source": [
    "### Compute the vector representation of the sarcastic samples\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1901fd12-572e-4fed-8268-fb836e2f0ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, Vector{Int64}} with 13634 entries:\n",
       "  11950 => [2445, 8039, 4361, 1644, 6929, 18872, 21116, 0, 0, 0  …  0, 0, 0, 0,…\n",
       "  1703  => [8235, 6706, 23706, 26825, 29322, 16579, 18614, 4067, 23171, 0  …  0…\n",
       "  18374 => [10012, 18295, 16585, 29537, 18114, 12256, 23171, 8928, 28692, 22341…\n",
       "  23970 => [5538, 6660, 17967, 28344, 26825, 13629, 19951, 26730, 18532, 9964  …\n",
       "  27640 => [16775, 18532, 1232, 11340, 4000, 26856, 15142, 5732, 18532, 19593  …\n",
       "  28576 => [2835, 21827, 26825, 1063, 19442, 21862, 25274, 0, 0, 0  …  0, 0, 0,…\n",
       "  2015  => [1186, 11384, 21508, 1308, 28959, 23869, 25236, 9661, 25316, 3600  ……\n",
       "  11280 => [17511, 4335, 3769, 4912, 26825, 26463, 15905, 9622, 0, 0  …  0, 0, …\n",
       "  28165 => [8862, 24741, 180, 4452, 18775, 9442, 18651, 10268, 2325, 24857  …  …\n",
       "  3220  => [2164, 12092, 29389, 25362, 14654, 13457, 26975, 0, 0, 0  …  0, 0, 0…\n",
       "  422   => [28824, 9634, 23167, 9136, 22506, 24022, 6440, 2325, 15284, 26651  ……\n",
       "  15370 => [3380, 16165, 11403, 17801, 29327, 14386, 0, 0, 0, 0  …  0, 0, 0, 0,…\n",
       "  15859 => [17801, 12007, 2295, 29241, 26528, 28939, 11318, 25575, 13457, 26566…\n",
       "  4030  => [9436, 18666, 18532, 16230, 20722, 27912, 26825, 11681, 0, 0  …  0, …\n",
       "  3163  => [19720, 13982, 12450, 21112, 10602, 28156, 7135, 0, 0, 0  …  0, 0, 0…\n",
       "  9523  => [2491, 23668, 19845, 27995, 28959, 10296, 10218, 20819, 15315, 18534…\n",
       "  25334 => [22720, 29257, 24087, 27995, 957, 12720, 3166, 24807, 17181, 18851  …\n",
       "  25581 => [21974, 18532, 22755, 13227, 23886, 18311, 13457, 24539, 10823, 0  ……\n",
       "  16341 => [17161, 16534, 4871, 3951, 14635, 2191, 6858, 18532, 9442, 12589  … …\n",
       "  23265 => [13319, 24982, 10918, 18882, 3576, 20036, 0, 0, 0, 0  …  0, 0, 0, 0,…\n",
       "  12797 => [4290, 13540, 10532, 18651, 13034, 22371, 12732, 29086, 23490, 12687…\n",
       "  14085 => [14153, 21528, 8737, 7256, 14140, 11993, 957, 26825, 24882, 13516  ……\n",
       "  27851 => [17210, 13350, 4606, 1421, 19629, 0, 0, 0, 0, 0  …  0, 0, 0, 0, 0, 0…\n",
       "  10454 => [23683, 14767, 5492, 11969, 10602, 19315, 15831, 4320, 18039, 0  …  …\n",
       "  24477 => [15221, 26533, 26104, 6106, 11993, 12735, 18532, 28995, 5808, 26989 …\n",
       "  ⋮     => ⋮"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcasim_sample_dictionary = Dict{Int64, Array{Int64,1}}();\n",
    "for i ∈ 1:number_of_records\n",
    "    is_sarcastic_flag = dataset.records[i].issarcastic\n",
    "    if (is_sarcastic_flag == true)\n",
    "        v = tokenize(dataset.records[i].headline, dataset.tokens, \n",
    "            pad = max_pad_length);        \n",
    "        sarcasim_sample_dictionary[i] = v;\n",
    "    end\n",
    "end\n",
    "sarcasim_sample_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca31698-606a-46c3-88f1-432ba362c354",
   "metadata": {},
   "source": [
    "### Compute the vector representation of the non-sarcastic samples\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bd142fc-70c3-44d3-8980-f3f07878af39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, Vector{Int64}} with 14985 entries:\n",
       "  12427 => [17646, 22222, 26825, 12326, 20944, 29191, 28513, 21851, 8482, 0  … …\n",
       "  7685  => [26617, 26362, 27361, 26825, 16116, 26533, 22567, 22966, 29483, 3016…\n",
       "  3406  => [11740, 15063, 1642, 6107, 26533, 20434, 18532, 6329, 13457, 20186  …\n",
       "  1090  => [5538, 1812, 27111, 15251, 24022, 23869, 29113, 13457, 18310, 0  …  …\n",
       "  18139 => [3841, 19962, 7649, 28806, 14099, 24646, 24646, 24646, 24646, 23208 …\n",
       "  17088 => [20832, 20914, 29113, 20689, 13457, 18251, 4680, 0, 0, 0  …  0, 0, 0…\n",
       "  16805 => [6360, 14099, 4039, 4502, 6090, 10346, 14140, 0, 0, 0  …  0, 0, 0, 0…\n",
       "  11251 => [26533, 27946, 27408, 1739, 18293, 3248, 17615, 26825, 2931, 26533  …\n",
       "  25327 => [26148, 29544, 14745, 26825, 29281, 7135, 22262, 13457, 18319, 17991…\n",
       "  8060  => [723, 28769, 26825, 6931, 28824, 6452, 1031, 26825, 28824, 20002  … …\n",
       "  14167 => [17739, 4489, 29086, 9773, 29191, 15044, 11060, 13457, 1670, 12940  …\n",
       "  8660  => [26533, 9718, 18797, 15497, 1739, 7183, 18532, 8924, 15004, 0  …  0,…\n",
       "  18475 => [14402, 15433, 29257, 2371, 5401, 22494, 17631, 18717, 2977, 27318  …\n",
       "  14221 => [10105, 6706, 14099, 26073, 18532, 16250, 18872, 13735, 0, 0  …  0, …\n",
       "  15545 => [16140, 5376, 26825, 21754, 12750, 22536, 13457, 17500, 23916, 11232…\n",
       "  3855  => [13034, 26533, 11672, 11465, 18982, 11740, 13583, 17637, 3053, 16035…\n",
       "  15916 => [28957, 28770, 4869, 18885, 7806, 28770, 16116, 913, 3193, 29302  … …\n",
       "  23629 => [15405, 7440, 9257, 22494, 10602, 9974, 7135, 0, 0, 0  …  0, 0, 0, 0…\n",
       "  22241 => [4979, 26533, 21442, 15253, 5172, 22191, 13457, 913, 19274, 26825  ……\n",
       "  2989  => [13068, 22531, 17387, 17990, 18514, 310, 0, 0, 0, 0  …  0, 0, 0, 0, …\n",
       "  4357  => [9432, 29181, 29537, 6467, 15645, 13782, 29544, 9992, 3694, 29537  ……\n",
       "  17494 => [28968, 14286, 23705, 3075, 19113, 14119, 20143, 26306, 22201, 0  … …\n",
       "  8552  => [16846, 16508, 14766, 15396, 26515, 913, 7135, 1289, 26156, 18556  ……\n",
       "  9266  => [19310, 12686, 13400, 14774, 14603, 10602, 14598, 28914, 9939, 15569…\n",
       "  23690 => [26740, 2361, 1739, 14773, 29648, 2325, 1711, 1783, 19312, 13457  … …\n",
       "  ⋮     => ⋮"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_sarcasim_sample_dictionary = Dict{Int64, Array{Int64,1}}();\n",
    "for i ∈ 1:number_of_records\n",
    "    is_sarcastic_flag = dataset.records[i].issarcastic\n",
    "    if (is_sarcastic_flag == false)\n",
    "        v = tokenize(dataset.records[i].headline, dataset.tokens, \n",
    "            pad = max_pad_length);        \n",
    "        non_sarcasim_sample_dictionary[i] = v;\n",
    "    end\n",
    "end\n",
    "non_sarcasim_sample_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7b39489-a508-4e1a-a8ea-789bfd919030",
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert length(non_sarcasim_sample_dictionary) == number_of_non_sarcasm_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede85064-05f5-495a-b3d8-665320d03c42",
   "metadata": {},
   "source": [
    "## Final: Save data to disk\n",
    "Finally, we did a bunch of stuff in this example, and we don't want to have to recompute the corpus, token dictionary, etc. So let's save it [in an HDF5 encoded binary file](https://en.wikipedia.org/wiki/Hierarchical_Data_Format). To start, specify a path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ed269d6-4f4f-4e30-a7c7-f9f472351d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save_file = joinpath(_PATH_TO_DATA, \"L4a-SarcasmSamplesTokenizer-SavedData.jld2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033a917a-8f05-4049-8d63-3d40ad1d4185",
   "metadata": {},
   "source": [
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca9fba63-0141-4187-95d1-907a91d4ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(path_to_save_file, Dict(\"tokendictionary\" => tokendictionary, \n",
    "        \"dataset\" => dataset, \"number_of_records\" => number_of_records));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db248e1f-4114-445a-85b7-46b433251941",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
