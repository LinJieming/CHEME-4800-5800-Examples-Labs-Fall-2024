{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51dba82a-3861-41d1-beed-db31ad8afd46",
   "metadata": {},
   "source": [
    "# Example: Loading and Analyzing the Sarcasm Dataset\n",
    "Fill me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69630fa3-1f48-4773-a08a-316ac749a680",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We set up the computational environment by including [the `Include. jl` file](Include.jl) using [the `include(...)` method](https://docs.julialang.org/en/v1/base/base/#Base.include). The [`Include.jl` file](Include.jl) loads external packages and functions we will use in these examples. \n",
    "* For additional information on functions and types used in this example, see the [Julia programming language documentation](https://docs.julialang.org/en/v1/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee9ce5a-bcd7-4e5a-890e-7fd1dc43c799",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316f88aa-17e9-492b-b7c1-63c57c930297",
   "metadata": {},
   "source": [
    "## Task 1: Load the sarcasm dataset\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167d0489-7541-48a7-9d04-dbb0c651f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusmodel = joinpath(_PATH_TO_DATA, \"Sarcasm_Headlines_Dataset_v2.txt\") |> corpus;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4c73e-d6e3-438a-bd0e-1551f2d1a8c5",
   "metadata": {},
   "source": [
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b93c527-3b77-4b11-8f47-01f62144aacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MySarcasmRecordModel(true, \"thirtysomething scientists unveil doomsday clock of hair loss\", \"https://www.theonion.com/thirtysomething-scientists-unveil-doomsday-clock-of-hai-1819586205\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpusmodel.records[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c83f2903-67f8-42b7-bd8e-9e1ffae59c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, MySarcasmRecordModel}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(corpusmodel.records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cba7185-3d09-4ff9-a062-3b5a952198af",
   "metadata": {},
   "source": [
    "## Task 2: Build the tokens dictionary\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a182fa-6292-4363-8043-a600e5d7e48d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1ec9ae4-9c62-4332-98bd-d7212b2526ec",
   "metadata": {},
   "source": [
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b394822-694d-4c5a-848b-4f339c894fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenarray = Array{String,1}();\n",
    "for (k,v) ∈ corpusmodel.records\n",
    "\n",
    "    # process headline data -\n",
    "    headline = v.headline;\n",
    "    tokens = split(headline, \" \") .|> String;\n",
    "\n",
    "    # process -\n",
    "    for token ∈ tokens\n",
    "\n",
    "        # strip any leading or trailing spaces -\n",
    "        token = strip(token, ' ');\n",
    "        \n",
    "        if (in(token, tokenarray) == false && isempty(token) == false)\n",
    "            push!(tokenarray, token);\n",
    "        end\n",
    "    end \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeec749b-dec4-41a7-bc33-a3762aa5c5d0",
   "metadata": {},
   "source": [
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f78b0b5-4027-47b2-a9b1-a5bab2bef31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29662-element Vector{String}:\n",
       " \"#\"\n",
       " \"##\"\n",
       " \"#1\"\n",
       " \"#11717\"\n",
       " \"#4\"\n",
       " \"#5\"\n",
       " \"#addcandytoamovie\"\n",
       " \"#addclimatechangetotv\"\n",
       " \"#alohahuffpost\"\n",
       " \"#alternativefacts\"\n",
       " \"#badpicturemonday\"\n",
       " \"#blacklivesmatter\"\n",
       " \"#brownribboncampaign\"\n",
       " ⋮\n",
       " \"zoologists\"\n",
       " \"zoomed\"\n",
       " \"zoos\"\n",
       " \"zoroastrianism\"\n",
       " \"zs\"\n",
       " \"zsa\"\n",
       " \"zucker\"\n",
       " \"zuckerberg\"\n",
       " \"zuckerbergs\"\n",
       " \"zz\"\n",
       " \"éclairs\"\n",
       " \"ünited\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenarray |> sort!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed3e4789-2d11-4a42-93d5-952b36529b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"jacquie\" ∈ tokenarray "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0fbd42-56fa-4fe6-b0ae-86b59d550161",
   "metadata": {},
   "source": [
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26e38220-e676-4953-ae81-862c552d46f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokendictionary = Dict{String, Int64}();\n",
    "inverse = Dict{Int64, String}();\n",
    "for i ∈ eachindex(tokenarray)\n",
    "    key = tokenarray[i]\n",
    "    tokendictionary[key] = i; \n",
    "    inverse[i] = key;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae90c592-faae-42e4-91f7-8b5231068d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Int64} with 29662 entries:\n",
       "  \"rosecolored\"           => 22746\n",
       "  \"trumpland\"             => 27336\n",
       "  \"irreplaceable\"         => 14091\n",
       "  \"cluelessly\"            => 5597\n",
       "  \"syriaalthough\"         => 26086\n",
       "  \"bumbum\"                => 4204\n",
       "  \"#addclimatechangetotv\" => 8\n",
       "  \"dumber\"                => 8590\n",
       "  \"daraya\"                => 7072\n",
       "  \"jakrapong\"             => 14213\n",
       "  \"henry\"                 => 12550\n",
       "  \"skylight\"              => 24355\n",
       "  \"bidder\"                => 3239\n",
       "  \"abducted\"              => 934\n",
       "  \"rises\"                 => 22533\n",
       "  \"hampshire\"             => 12131\n",
       "  \"droogs\"                => 8492\n",
       "  \"whiz\"                  => 29009\n",
       "  \"buffetts\"              => 4152\n",
       "  \"il\"                    => 13307\n",
       "  \"celebfilled\"           => 4868\n",
       "  \"msnbc\"                 => 17516\n",
       "  \"starches\"              => 25204\n",
       "  \"tribunal\"              => 27224\n",
       "  \"lovers\"                => 15869\n",
       "  ⋮                       => ⋮"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokendictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dffdf9-1b61-4904-9128-4a6fc3afe560",
   "metadata": {},
   "source": [
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab0d7ef9-0d5c-4a37-8129-dd1b352fd7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusmodel.tokens = tokendictionary;\n",
    "corpusmodel.inverse = inverse;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e58e3-e33b-45bb-8dab-1ef64d4b2679",
   "metadata": {},
   "source": [
    "## Task 3: Tokenize headline records\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9b8f587-b23d-43eb-89be-df739f0c8ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_records = corpusmodel.records |> length; # what is going on here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b88331-3b29-4b31-beb0-5c0b33b0303d",
   "metadata": {},
   "source": [
    "### Look at a random record\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af4c6ce8-9464-4e6a-aac1-ce96d18a85fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MySarcasmRecordModel(true, \"world health organization not sure how but adam levines new fragrance the only antidote to mers virus\", \"https://www.theonion.com/world-health-organization-not-sure-how-but-adam-levi-1819575159\")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_test_record = rand(1:number_of_records) |> i -> corpusmodel.records[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4aaee86-09cf-4253-83df-6df46e1f571e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"world health organization not sure how but adam levines new fragrance the only antidote to mers virus\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_test_record.headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5add6a7f-6849-425d-9340-31c2208d9263",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `dataset` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `dataset` not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[25]:1"
     ]
    }
   ],
   "source": [
    "tv = tokenize(random_test_record.headline, corpusmodel.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523b4fca-8ae8-4aa5-9467-2966d8459035",
   "metadata": {},
   "source": [
    "### Compute the maximum pad length\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48bc335b-be7d-4c63-b8d8-25fea7aff46e",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `dataset` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `dataset` not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[27]:3"
     ]
    }
   ],
   "source": [
    "max_pad_length = 0;\n",
    "for i ∈ 1:number_of_records\n",
    "    test_record_length = tokenize(corpusmodel.records[i].headline, corpusmodel.tokens) |> length;\n",
    "    if (test_record_length > max_pad_length)\n",
    "        max_pad_length = test_record_length;\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b802fe64-6dff-413e-a9da-0894de6b27ad",
   "metadata": {},
   "source": [
    "### Compute the number of sarcasm and non-sarcasm samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b03656-a739-46d9-9c47-c9acb2aa9edb",
   "metadata": {},
   "source": [
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2071212-6729-43b0-95c9-27d44c07723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_sarcasm_samples = 0;\n",
    "number_of_non_sarcasm_samples = 0;\n",
    "for i ∈ 1:number_of_records\n",
    "    \n",
    "    is_sarcastic_flag = corpusmodel.records[i].issarcastic\n",
    "    if (is_sarcastic_flag == true)\n",
    "        number_of_sarcasm_samples += 1;\n",
    "    else\n",
    "        number_of_non_sarcasm_samples+=1;\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4b7ba5-4690-4671-9034-327b409eaf2d",
   "metadata": {},
   "source": [
    "### Compute the vector representation of the sarcastic samples\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1901fd12-572e-4fed-8268-fb836e2f0ab7",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `dataset` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `dataset` not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[32]:5"
     ]
    }
   ],
   "source": [
    "sarcasim_sample_dictionary = Dict{Int64, Array{Int64,1}}();\n",
    "for i ∈ 1:number_of_records\n",
    "    is_sarcastic_flag = corpusmodel.records[i].issarcastic\n",
    "    if (is_sarcastic_flag == true)\n",
    "        v = tokenize(corpusmodel.records[i].headline, corpusmodel.tokens, \n",
    "            pad = max_pad_length);        \n",
    "        sarcasim_sample_dictionary[i] = v;\n",
    "    end\n",
    "end\n",
    "sarcasim_sample_dictionary[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca31698-606a-46c3-88f1-432ba362c354",
   "metadata": {},
   "source": [
    "### Compute the vector representation of the non-sarcastic samples\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bd142fc-70c3-44d3-8980-f3f07878af39",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `dataset` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `dataset` not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[34]:5"
     ]
    }
   ],
   "source": [
    "non_sarcasim_sample_dictionary = Dict{Int64, Array{Int64,1}}();\n",
    "for i ∈ 1:number_of_records\n",
    "    is_sarcastic_flag = corpusmodel.records[i].issarcastic\n",
    "    if (is_sarcastic_flag == false)\n",
    "        v = tokenize(corpusmodel.records[i].headline, corpusmodel.tokens, \n",
    "            pad = max_pad_length);        \n",
    "        non_sarcasim_sample_dictionary[i] = v;\n",
    "    end\n",
    "end\n",
    "non_sarcasim_sample_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7b39489-a508-4e1a-a8ea-789bfd919030",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "AssertionError: length(non_sarcasim_sample_dictionary) == number_of_non_sarcasm_samples",
     "output_type": "error",
     "traceback": [
      "AssertionError: length(non_sarcasim_sample_dictionary) == number_of_non_sarcasm_samples",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[35]:1"
     ]
    }
   ],
   "source": [
    "@assert length(non_sarcasim_sample_dictionary) == number_of_non_sarcasm_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede85064-05f5-495a-b3d8-665320d03c42",
   "metadata": {},
   "source": [
    "## Final: Save data to disk\n",
    "Finally, we did a bunch of stuff in this example, and we don't want to have to recompute the corpus, token dictionary, etc. So let's save it [in an HDF5 encoded binary file](https://en.wikipedia.org/wiki/Hierarchical_Data_Format). To start, specify a path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ed269d6-4f4f-4e30-a7c7-f9f472351d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save_file = joinpath(_PATH_TO_DATA, \"L4a-SarcasmSamplesTokenizer-SavedData.jld2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033a917a-8f05-4049-8d63-3d40ad1d4185",
   "metadata": {},
   "source": [
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca9fba63-0141-4187-95d1-907a91d4ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(path_to_save_file, Dict(\"tokendictionary\" => tokendictionary, \n",
    "        \"corpus\" => corpusmodel, \"number_of_records\" => number_of_records));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db248e1f-4114-445a-85b7-46b433251941",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
